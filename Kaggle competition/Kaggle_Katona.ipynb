{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dabad94-026b-4a93-b5cd-bc2c9482684f",
   "metadata": {},
   "source": [
    "# <center>Classifying fashion images on the MNIST data<center>\n",
    "    \n",
    "<center>Created by Zsófia Rebeka Katona<center>\n",
    "<center>Data Science 2 - Kaggle competition<center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b707ed-ccd1-470d-aab2-2895d50fa7c6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---\n",
    "\n",
    "The goal of this challenge is to predict which articles are shared the most on social media. The data comes from the website mashable.com as of the beginning of 2015. The dataset used in the competition can be found in the UCI repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0a76d-458e-44a4-a207-8816375c9330",
   "metadata": {},
   "source": [
    "- You will find the training and test data in the data section of the competition, along with a description of the features. - You will need to build models on the training data and make predictions on the test data and submit your solutions to Kaggle. You will also find a sample solution file in the data section that shows the format you will need to use for your own submissions.\n",
    "- The deadline for Kaggle solutions is 8PM on 19 April. You will be graded primarily on the basis of your work and how clearly you explain your methods and results. Those in the top three in the competition will receive some extra points. I expect you to experiment with all the methods we have covered: linear models, random forest, gradient boosting, neural networks + parameter tuning, feature engineering.\n",
    "- You will see the public score of your best model on the leaderboard. A private dataset will be used to evaluate the final performance of your model to avoid overfitting based on the leaderboard.\n",
    "- You should also submit to Moodle the documentation (ipynb and pdf) of your work, including exploratory data analysis, data cleaning, parameter tuning and evaluation. Aim for concise explanations.\n",
    "- Feel free to ask questions about the task in Slack. The Kaggle competition is already open, please start working on it and submitting solutions (you cannot submit more than 5 solutions per day)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd8f068-74a2-4326-ad6e-d7f708948697",
   "metadata": {},
   "source": [
    "## Data import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2b8cc9-4dc8-446b-a8c8-f20a6122d776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d9c7a2-fafc-4a97-9bfd-22f77f935d6e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train set is: (29733, 61).\n",
      "The shape of the test set is (9911, 60).\n",
      "The data types of the train set:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29733 entries, 0 to 29732\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   timedelta                      29733 non-null  int64  \n",
      " 1   n_tokens_title                 29733 non-null  int64  \n",
      " 2   n_tokens_content               29733 non-null  int64  \n",
      " 3   n_unique_tokens                29733 non-null  float64\n",
      " 4   n_non_stop_words               29733 non-null  float64\n",
      " 5   n_non_stop_unique_tokens       29733 non-null  float64\n",
      " 6   num_hrefs                      29733 non-null  int64  \n",
      " 7   num_self_hrefs                 29733 non-null  int64  \n",
      " 8   num_imgs                       29733 non-null  int64  \n",
      " 9   num_videos                     29733 non-null  int64  \n",
      " 10  average_token_length           29733 non-null  float64\n",
      " 11  num_keywords                   29733 non-null  int64  \n",
      " 12  data_channel_is_lifestyle      29733 non-null  int64  \n",
      " 13  data_channel_is_entertainment  29733 non-null  int64  \n",
      " 14  data_channel_is_bus            29733 non-null  int64  \n",
      " 15  data_channel_is_socmed         29733 non-null  int64  \n",
      " 16  data_channel_is_tech           29733 non-null  int64  \n",
      " 17  data_channel_is_world          29733 non-null  int64  \n",
      " 18  kw_min_min                     29733 non-null  int64  \n",
      " 19  kw_max_min                     29733 non-null  float64\n",
      " 20  kw_avg_min                     29733 non-null  float64\n",
      " 21  kw_min_max                     29733 non-null  int64  \n",
      " 22  kw_max_max                     29733 non-null  int64  \n",
      " 23  kw_avg_max                     29733 non-null  float64\n",
      " 24  kw_min_avg                     29733 non-null  float64\n",
      " 25  kw_max_avg                     29733 non-null  float64\n",
      " 26  kw_avg_avg                     29733 non-null  float64\n",
      " 27  self_reference_min_shares      29733 non-null  float64\n",
      " 28  self_reference_max_shares      29733 non-null  float64\n",
      " 29  self_reference_avg_sharess     29733 non-null  float64\n",
      " 30  weekday_is_monday              29733 non-null  int64  \n",
      " 31  weekday_is_tuesday             29733 non-null  int64  \n",
      " 32  weekday_is_wednesday           29733 non-null  int64  \n",
      " 33  weekday_is_thursday            29733 non-null  int64  \n",
      " 34  weekday_is_friday              29733 non-null  int64  \n",
      " 35  weekday_is_saturday            29733 non-null  int64  \n",
      " 36  weekday_is_sunday              29733 non-null  int64  \n",
      " 37  is_weekend                     29733 non-null  int64  \n",
      " 38  LDA_00                         29733 non-null  float64\n",
      " 39  LDA_01                         29733 non-null  float64\n",
      " 40  LDA_02                         29733 non-null  float64\n",
      " 41  LDA_03                         29733 non-null  float64\n",
      " 42  LDA_04                         29733 non-null  float64\n",
      " 43  global_subjectivity            29733 non-null  float64\n",
      " 44  global_sentiment_polarity      29733 non-null  float64\n",
      " 45  global_rate_positive_words     29733 non-null  float64\n",
      " 46  global_rate_negative_words     29733 non-null  float64\n",
      " 47  rate_positive_words            29733 non-null  float64\n",
      " 48  rate_negative_words            29733 non-null  float64\n",
      " 49  avg_positive_polarity          29733 non-null  float64\n",
      " 50  min_positive_polarity          29733 non-null  float64\n",
      " 51  max_positive_polarity          29733 non-null  float64\n",
      " 52  avg_negative_polarity          29733 non-null  float64\n",
      " 53  min_negative_polarity          29733 non-null  float64\n",
      " 54  max_negative_polarity          29733 non-null  float64\n",
      " 55  title_subjectivity             29733 non-null  float64\n",
      " 56  title_sentiment_polarity       29733 non-null  float64\n",
      " 57  abs_title_subjectivity         29733 non-null  float64\n",
      " 58  abs_title_sentiment_polarity   29733 non-null  float64\n",
      " 59  is_popular                     29733 non-null  int64  \n",
      " 60  article_id                     29733 non-null  int64  \n",
      "dtypes: float64(34), int64(27)\n",
      "memory usage: 13.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Importing the training and the test set\n",
    "current_dir = os.getcwd()\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Checking the attributes of the sets\n",
    "print(f\"The shape of the train set is: {train_df.shape}.\")\n",
    "print(f\"The shape of the test set is {test_df.shape}.\")\n",
    "print(\"The data types of the train set:\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815a2975-5f9d-410b-b9d4-c059fa72d231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>is_popular</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>702</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.153395</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346</td>\n",
       "      <td>8</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.470143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666209</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308167</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484</td>\n",
       "      <td>9</td>\n",
       "      <td>214</td>\n",
       "      <td>0.618090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>-0.141667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>249</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664740</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>12</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.397841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583578</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>568</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>318</td>\n",
       "      <td>12</td>\n",
       "      <td>1422</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.469256</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.234167</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>582</td>\n",
       "      <td>6</td>\n",
       "      <td>1102</td>\n",
       "      <td>0.451287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.642089</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.151630</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>269</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>567</td>\n",
       "      <td>7</td>\n",
       "      <td>94</td>\n",
       "      <td>0.755319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.183333</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0        594               9               702         0.454545   \n",
       "1        346               8              1197         0.470143   \n",
       "2        484               9               214         0.618090   \n",
       "3        639               8               249         0.621951   \n",
       "4        177              12              1219         0.397841   \n",
       "5        568               7               126         0.723577   \n",
       "6        318              12              1422         0.367994   \n",
       "7        582               6              1102         0.451287   \n",
       "8        269               9                 0         0.000000   \n",
       "9        567               7                94         0.755319   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0               1.0                  0.620438         11               2   \n",
       "1               1.0                  0.666209         21               6   \n",
       "2               1.0                  0.748092          5               2   \n",
       "3               1.0                  0.664740         16               5   \n",
       "4               1.0                  0.583578         21               1   \n",
       "5               1.0                  0.774194          3               3   \n",
       "6               1.0                  0.469256         28              28   \n",
       "7               1.0                  0.642089          7               3   \n",
       "8               0.0                  0.000000          0               0   \n",
       "9               1.0                  0.812500          8               6   \n",
       "\n",
       "   num_imgs  num_videos  ...  max_positive_polarity  avg_negative_polarity  \\\n",
       "0         1           0  ...               1.000000              -0.153395   \n",
       "1         2          13  ...               1.000000              -0.308167   \n",
       "2         1           0  ...               0.433333              -0.141667   \n",
       "3         8           0  ...               0.500000              -0.500000   \n",
       "4         1           2  ...               0.800000              -0.441111   \n",
       "5         1           0  ...               0.285714               0.000000   \n",
       "6        26           0  ...               0.700000              -0.234167   \n",
       "7         1           0  ...               0.800000              -0.151630   \n",
       "8         5           0  ...               0.000000               0.000000   \n",
       "9         0          11  ...               1.000000              -0.183333   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                   -0.4              -0.100000            0.000000   \n",
       "1                   -1.0              -0.100000            0.000000   \n",
       "2                   -0.2              -0.050000            0.000000   \n",
       "3                   -0.8              -0.400000            0.000000   \n",
       "4                   -1.0              -0.050000            0.000000   \n",
       "5                    0.0               0.000000            0.454545   \n",
       "6                   -0.5              -0.050000            1.000000   \n",
       "7                   -0.4              -0.050000            0.800000   \n",
       "8                    0.0               0.000000            0.500000   \n",
       "9                   -0.2              -0.166667            0.000000   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                  0.000000                0.500000   \n",
       "1                  0.000000                0.500000   \n",
       "2                  0.000000                0.500000   \n",
       "3                  0.000000                0.500000   \n",
       "4                  0.000000                0.500000   \n",
       "5                  0.136364                0.045455   \n",
       "6                  0.100000                0.500000   \n",
       "7                  0.400000                0.300000   \n",
       "8                  0.500000                0.000000   \n",
       "9                  0.000000                0.500000   \n",
       "\n",
       "   abs_title_sentiment_polarity  is_popular  article_id  \n",
       "0                      0.000000           0           1  \n",
       "1                      0.000000           0           3  \n",
       "2                      0.000000           0           5  \n",
       "3                      0.000000           0           6  \n",
       "4                      0.000000           0           7  \n",
       "5                      0.136364           0           8  \n",
       "6                      0.100000           0           9  \n",
       "7                      0.400000           1          11  \n",
       "8                      0.500000           0          12  \n",
       "9                      0.000000           0          14  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a825f1c-2bda-48eb-98d4-fd7b3a7c4008",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc3ac9-e82b-4513-b948-43de63ae28fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dropping the target variable\n",
    "features = train_df.drop(columns=[\"is_popular\"])\n",
    "label = train_df[\"is_popular\"]\n",
    "\n",
    "# Setting the random state\n",
    "prng = np.random.RandomState(20240419)\n",
    "\n",
    "# Splitting the fata\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=prng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec37f8-0e04-4b96-84ff-15b41fe21b8f",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66af82-1007-4932-b68a-503e3ba52630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the feature engineerined dataset\n",
    "def extract_dt_features(df_with_datetime):\n",
    "    df_with_datetime['timedelta'] = pd.to_datetime(df_with_datetime['timdelta'], utc=True)\n",
    "    df_with_datetime['month'] = df_with_datetime['datetime'].dt.month\n",
    "    df_with_datetime['day'] = df_with_datetime['datetime'].dt.day\n",
    "    \n",
    "# Adding the total number of media elements in each post (links, videos, images)\n",
    "train_df['total_multimedia'] = train_df['num_hrefs'] + train_df['num_self_hrefs'] + train_df['num_imgs'] + train_df['num_videos']\n",
    "    \n",
    "# Extracting the features\n",
    "extract_dt_features(train_df)\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "feature_matrix = bike_data.drop(columns=[\"count\", \"registered\", \"casual\"]).select_dtypes(include=np.number)\n",
    "\n",
    "# We label the count column\n",
    "label = bike_data[\"count\"]\n",
    "\n",
    "# Setting the random pseudo state again\n",
    "prng = np.random.RandomState(20240306)\n",
    "# Splitting the fe training set and test set again\n",
    "X_train_fe, X_test_fe, y_train, y_test = train_test_split(feature_matrix, label, test_size=0.2, random_state=prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8229246-16c0-4df7-83f4-dd9cbe6e3c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac506ba-5680-4af0-939c-7f5f6b73cccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745589a0-7ff5-4652-acfb-de443649c2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db6355e-9abd-4308-8326-6bf3ebddb4e8",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c013d5e-101f-4b7e-a557-dfa9175db17c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23902696-c361-4765-ad09-7cd07acd2f97",
   "metadata": {},
   "source": [
    "## Predictive models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee7185-eb49-41d3-b393-aa3e6afab017",
   "metadata": {},
   "source": [
    "### Model 1: Linear models (OLS)\n",
    "Using 6 different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a4a08-8e82-4ff8-bc54-f4ba68833ef3",
   "metadata": {},
   "source": [
    "### Model 2: Linear models (Lasso)\n",
    "Using the same 6 different models\n",
    "Logit + lasso with CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897c8a1-c50b-4296-a40a-9e4988d3ffc9",
   "metadata": {},
   "source": [
    "### Model 3: Decision Trees\n",
    "and fearure engineered decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c98676-ca55-4f16-9c65-b72a8375efbe",
   "metadata": {},
   "source": [
    "### Model 4: RandomForest\n",
    "with cross-validation +\n",
    "or feature engineered RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac3d30-2fe0-44b6-bd2d-4e016e554b8b",
   "metadata": {},
   "source": [
    "### Model 5: Gradient Boosting\n",
    "with cross-validation + or feature engineered GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377d0e5-9766-4350-9612-eb4fc6c19c67",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968d8e1-3861-464c-8866-9eefe491e753",
   "metadata": {},
   "source": [
    "### Model 6\n",
    "Simple fully connected layer network with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd409ed-8a02-41d3-be4e-5e6d284dac99",
   "metadata": {},
   "source": [
    "### Model 7\n",
    "Convolutional neural network with dropout and increased width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798ef34-b89e-432e-b32e-c77f67e7a74b",
   "metadata": {},
   "source": [
    "### Model 8\n",
    "Convolutional neural network with dropout, increased width and increased depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e44d46-d78a-4e4c-ba76-ff3703dbcb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d47f0962-d1f0-4a82-b75b-3486cdb1ad94",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c4bdc-606b-4557-a8d1-703c688b7bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
